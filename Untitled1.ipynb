{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of given Image List 750\n",
      "Number of images -  751\n",
      "Training Set Size :  675\n",
      "Test Set Size :  76\n",
      "Length of training Image List 674\n",
      "Length of testing Image List 76\n",
      "Normal Credit - Sigmoid\n",
      "Device: cpu\n",
      "Length of Augmented Dataset 6740\n",
      "Run - epoch: 100 lr: 0.001 weight_decay:1e-05\n",
      "Activation Function:  sigmoid\n",
      "..Colorizer Training started..\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "\n",
    "import buildDataset\n",
    "from Colorize_deep import Colorize_deep\n",
    "from Constants import Constants\n",
    "from utils import Utils\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    image_list = glob.glob('face_images/*.jpg')\n",
    "    print(\"Length of given Image List\", len(image_list))\n",
    "\n",
    "    Utils().train_test_split()\n",
    "\n",
    "    training_image_list = glob.glob('data/train/class/*.jpg')\n",
    "    # validation_image_list = glob.glob('data/val/class/*.jpg')\n",
    "    test_image_list = glob.glob('data/test/class/*.jpg')\n",
    "\n",
    "    print(\"Length of training Image List\", len(training_image_list))\n",
    "    # print(\"Length of validation Image List\", len(validation_image_list))\n",
    "    print(\"Length of testing Image List\", len(test_image_list))\n",
    "\n",
    "\n",
    "def build_dataset(cuda=False, num_workers=1,\n",
    "                  activation_function=Constants.SIGMOID):\n",
    "    # define pytorch transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(128),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomResizedCrop(128)\n",
    "    ])\n",
    "\n",
    "    train_datasets = []\n",
    "    if activation_function == Constants.SIGMOID or activation_function == Constants.TANH:\n",
    "        train_datasets.append(buildDataset.AugmentImageDataset('data/train'))\n",
    "    elif activation_function == Constants.RELU:\n",
    "        train_datasets.append(buildDataset.AugmentImageDataset_RELU('data/train'))\n",
    "\n",
    "    for i in range(9):\n",
    "        if activation_function == Constants.SIGMOID:\n",
    "            train_datasets.append(buildDataset.AugmentImageDataset('data/train', transform))\n",
    "        elif activation_function == Constants.RELU:\n",
    "            train_datasets.append(buildDataset.AugmentImageDataset_RELU('data/train', transform))\n",
    "        elif activation_function == Constants.TANH:\n",
    "            train_datasets.append(buildDataset.AugmentImageDataset_Tanh('data/train',\n",
    "                                                                        transform))\n",
    "\n",
    "    augmented_dataset = ConcatDataset(train_datasets)\n",
    "    print(\"Length of Augmented Dataset\", len(augmented_dataset))\n",
    "\n",
    "    train_loader_args = dict(shuffle=True,\n",
    "                             batch_size=Constants.REGRESSOR_BATCH_SIZE_CUDA,\n",
    "                             num_workers=num_workers, pin_memory=True) \\\n",
    "        if cuda else dict(shuffle=True, batch_size=Constants.REGRESSOR_BATCH_SIZE_CPU)\n",
    "\n",
    "    augmented_dataset_batch_train = DataLoader(dataset=augmented_dataset, **train_loader_args)\n",
    "    # augmented_dataset_batch_val = DataLoader(dataset=buildDataset.AugmentImageDataset('data/val'))\n",
    "    augmented_dataset_batch_test = DataLoader(dataset=buildDataset.AugmentImageDataset('data/test'))\n",
    "\n",
    "    return augmented_dataset_batch_train, augmented_dataset_batch_test\n",
    "\n",
    "\n",
    "def execute_colorizer_tanh():\n",
    "    activation_function = Constants.TANH\n",
    "    save_path = {'grayscale': 'outputs_tanh/gray/', 'colorized': 'outputs_tanh/color/'}\n",
    "    device, is_cuda_present, num_workers = Utils.get_device()\n",
    "    model_name = Constants.COLORIZER_SAVED_MODEL_PATH_TANH\n",
    "\n",
    "    print(\"Device: {0}\".format(device))\n",
    "    augmented_dataset_batch_train, \\\n",
    "    augmented_dataset_batch_test = build_dataset(is_cuda_present, num_workers,\n",
    "                                                 activation_function)\n",
    "\n",
    "    colorizer_deep = Colorize_deep()\n",
    "    colorizer_deep.train_colorizer(augmented_dataset_batch_train,\n",
    "                                    activation_function, model_name, device)\n",
    "\n",
    "    colorizer_deep.test_colorizer(augmented_dataset_batch_test, activation_function,\n",
    "                                  save_path, model_name, device)\n",
    "\n",
    "    colorizer_deep.train_regressor(augmented_dataset_batch_train, device)\n",
    "    colorizer_deep.test_regressor(augmented_dataset_batch_test, device)\n",
    "\n",
    "\n",
    "def execute_colorizer_sigmoid():\n",
    "    activation_function = Constants.SIGMOID\n",
    "    save_path = {'grayscale': 'outputs_sigmoid/gray/', 'colorized': 'outputs_sigmoid/color/'}\n",
    "    device, is_cuda_present, num_workers = Utils.get_device()\n",
    "    model_name = Constants.COLORIZER_SAVED_MODEL_PATH_SIGMOID\n",
    "\n",
    "    print(\"Device: {0}\".format(device))\n",
    "    augmented_dataset_batch_train, \\\n",
    "    augmented_dataset_batch_test = build_dataset(is_cuda_present, num_workers,\n",
    "                                                 activation_function)\n",
    "\n",
    "    colorizer_deep = Colorize_deep()\n",
    "    colorizer_deep.train_colorizer(augmented_dataset_batch_train,\n",
    "                                   activation_function, model_name, device)\n",
    "\n",
    "    colorizer_deep.test_colorizer(augmented_dataset_batch_test, activation_function,\n",
    "                                  save_path, model_name, device)\n",
    "\n",
    "    colorizer_deep.train_regressor(augmented_dataset_batch_train, device)\n",
    "    colorizer_deep.test_regressor(augmented_dataset_batch_test, device)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    load_data()\n",
    "\n",
    "    print(\"Normal Credit - Sigmoid\")\n",
    "    execute_colorizer_sigmoid()\n",
    "\n",
    "    print(\"Extra Credit - Tanh\")\n",
    "    execute_colorizer_tanh()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NGC-PyTorch-1.9",
   "language": "python",
   "name": "ngc-pytorch-1.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
